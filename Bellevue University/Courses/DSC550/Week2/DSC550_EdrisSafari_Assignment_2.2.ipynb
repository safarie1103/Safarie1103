{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file ='controversial-comments.jsonl'\n",
    "# possible orient value: split, records, index, columns, and values)\n",
    "# The following file is a subset of above file with the 1st 233537 lines.\n",
    "dataframe = pd.read_json(\"controversial-comments_small.jsonl\",orient=\"columns\",lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-0f1a6956b8bc>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdataframe\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtxt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhead\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "dataframe.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "def ToLower(string: str) -> str:\n",
    "    return string.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Convert all text to lowercase letters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>lower_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Well it's great that he did something about th...</td>\n",
       "      <td>well it's great that he did something about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You are right Mr. President.</td>\n",
       "      <td>you are right mr. president.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>You have given no input apart from saying I am...</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I get the frustration but the reason they want...</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I am far from an expert on TPP and I would ten...</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt  \\\n",
       "0    0  Well it's great that he did something about th...   \n",
       "1    0                       You are right Mr. President.   \n",
       "2    0  You have given no input apart from saying I am...   \n",
       "3    0  I get the frustration but the reason they want...   \n",
       "4    0  I am far from an expert on TPP and I would ten...   \n",
       "\n",
       "                                           lower_txt  \n",
       "0  well it's great that he did something about th...  \n",
       "1                       you are right mr. president.  \n",
       "2  you have given no input apart from saying i am...  \n",
       "3  i get the frustration but the reason they want...  \n",
       "4  i am far from an expert on tpp and i would ten...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['lower_txt'] = [ToLower(string) for string in dataframe['txt']]\n",
    "dataframe.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Remove all punctuation from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>lower_txt</th>\n",
       "      <th>NoPunctxt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Well it's great that he did something about th...</td>\n",
       "      <td>well it's great that he did something about th...</td>\n",
       "      <td>Well its great that he did something about tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You are right Mr. President.</td>\n",
       "      <td>you are right mr. president.</td>\n",
       "      <td>You are right Mr President</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>You have given no input apart from saying I am...</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "      <td>You have given no input apart from saying I am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I get the frustration but the reason they want...</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "      <td>I get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I am far from an expert on TPP and I would ten...</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "      <td>I am far from an expert on TPP and I would ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt  \\\n",
       "0    0  Well it's great that he did something about th...   \n",
       "1    0                       You are right Mr. President.   \n",
       "2    0  You have given no input apart from saying I am...   \n",
       "3    0  I get the frustration but the reason they want...   \n",
       "4    0  I am far from an expert on TPP and I would ten...   \n",
       "\n",
       "                                           lower_txt  \\\n",
       "0  well it's great that he did something about th...   \n",
       "1                       you are right mr. president.   \n",
       "2  you have given no input apart from saying i am...   \n",
       "3  i get the frustration but the reason they want...   \n",
       "4  i am far from an expert on tpp and i would ten...   \n",
       "\n",
       "                                           NoPunctxt  \n",
       "0  Well its great that he did something about tho...  \n",
       "1                         You are right Mr President  \n",
       "2  You have given no input apart from saying I am...  \n",
       "3  I get the frustration but the reason they want...  \n",
       "4  I am far from an expert on TPP and I would ten...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import unicodedata\n",
    "import sys\n",
    "\n",
    "# Create a dictionary of punctuation characters\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                            if unicodedata.category(chr(i)).startswith('P'))\n",
    "\n",
    "# For each string, remove any punctuation characters\n",
    "\n",
    "\n",
    "dataframe['NoPunctxt'] = [string.translate(punctuation) for string in dataframe['txt']]\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Remove stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NoPunctxt</th>\n",
       "      <th>Tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well its great that he did something about tho...</td>\n",
       "      <td>[Well, its, great, that, he, did, something, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are right Mr President</td>\n",
       "      <td>[You, are, right, Mr, President]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You have given no input apart from saying I am...</td>\n",
       "      <td>[You, have, given, no, input, apart, from, say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I get the frustration but the reason they want...</td>\n",
       "      <td>[I, get, the, frustration, but, the, reason, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am far from an expert on TPP and I would ten...</td>\n",
       "      <td>[I, am, far, from, an, expert, on, TPP, and, I...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           NoPunctxt  \\\n",
       "0  Well its great that he did something about tho...   \n",
       "1                         You are right Mr President   \n",
       "2  You have given no input apart from saying I am...   \n",
       "3  I get the frustration but the reason they want...   \n",
       "4  I am far from an expert on TPP and I would ten...   \n",
       "\n",
       "                                           Tokenized  \n",
       "0  [Well, its, great, that, he, did, something, a...  \n",
       "1                   [You, are, right, Mr, President]  \n",
       "2  [You, have, given, no, input, apart, from, say...  \n",
       "3  [I, get, the, frustration, but, the, reason, t...  \n",
       "4  [I, am, far, from, an, expert, on, TPP, and, I...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# Tokenize words\n",
    "dataframe['Tokenized'] = [word_tokenize(string) for string in dataframe['NoPunctxt']]\n",
    "dataframe[['NoPunctxt','Tokenized']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>NoStopWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>well its great that he did something about tho...</td>\n",
       "      <td>[well, its, great, that, he, did, something, a...</td>\n",
       "      <td>[well, great, something, beliefs, office, doub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr president</td>\n",
       "      <td>[you, are, right, mr, president]</td>\n",
       "      <td>[right, mr, president]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "      <td>[you, have, given, no, input, apart, from, say...</td>\n",
       "      <td>[given, input, apart, saying, wrong, argument,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "      <td>[i, get, the, frustration, but, the, reason, t...</td>\n",
       "      <td>[get, frustration, reason, want, way, foundati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "      <td>[i, am, far, from, an, expert, on, tpp, and, i...</td>\n",
       "      <td>[far, expert, tpp, would, tend, agree, lot, pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt  \\\n",
       "0    0  well its great that he did something about tho...   \n",
       "1    0                         you are right mr president   \n",
       "2    0  you have given no input apart from saying i am...   \n",
       "3    0  i get the frustration but the reason they want...   \n",
       "4    0  i am far from an expert on tpp and i would ten...   \n",
       "\n",
       "                                           Tokenized  \\\n",
       "0  [well, its, great, that, he, did, something, a...   \n",
       "1                   [you, are, right, mr, president]   \n",
       "2  [you, have, given, no, input, apart, from, say...   \n",
       "3  [i, get, the, frustration, but, the, reason, t...   \n",
       "4  [i, am, far, from, an, expert, on, tpp, and, i...   \n",
       "\n",
       "                                         NoStopWords  \n",
       "0  [well, great, something, beliefs, office, doub...  \n",
       "1                             [right, mr, president]  \n",
       "2  [given, input, apart, saying, wrong, argument,...  \n",
       "3  [get, frustration, reason, want, way, foundati...  \n",
       "4  [far, expert, tpp, would, tend, agree, lot, pr...  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# You will have to download the set of stop words the first time\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "# Load stop words\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Remove stop words\n",
    "dataframe['NoStopWords'] = dataframe['Tokenized'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D. Apply NLTKâ€™s PorterStemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "# Create stemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# Apply stemmer\n",
    "dataframe['PorterStemmer']  = dataframe['Tokenized'].apply(lambda x: [porter.stem(item) for item in x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>lower_txt</th>\n",
       "      <th>NoPunctxt</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>PorterStemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Well it's great that he did something about th...</td>\n",
       "      <td>well it's great that he did something about th...</td>\n",
       "      <td>Well its great that he did something about tho...</td>\n",
       "      <td>[Well, its, great, that, he, did, something, a...</td>\n",
       "      <td>[well, it, great, that, he, did, someth, about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You are right Mr. President.</td>\n",
       "      <td>you are right mr. president.</td>\n",
       "      <td>You are right Mr President</td>\n",
       "      <td>[You, are, right, Mr, President]</td>\n",
       "      <td>[you, are, right, Mr, presid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>You have given no input apart from saying I am...</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "      <td>You have given no input apart from saying I am...</td>\n",
       "      <td>[You, have, given, no, input, apart, from, say...</td>\n",
       "      <td>[you, have, given, no, input, apart, from, say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>I get the frustration but the reason they want...</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "      <td>I get the frustration but the reason they want...</td>\n",
       "      <td>[I, get, the, frustration, but, the, reason, t...</td>\n",
       "      <td>[I, get, the, frustrat, but, the, reason, they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I am far from an expert on TPP and I would ten...</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "      <td>I am far from an expert on TPP and I would ten...</td>\n",
       "      <td>[I, am, far, from, an, expert, on, TPP, and, I...</td>\n",
       "      <td>[I, am, far, from, an, expert, on, tpp, and, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Thanks for playing. [I feel like her now](http...</td>\n",
       "      <td>thanks for playing. [i feel like her now](http...</td>\n",
       "      <td>Thanks for playing I feel like her nowhttpsthe...</td>\n",
       "      <td>[Thanks, for, playing, I, feel, like, her, now...</td>\n",
       "      <td>[thank, for, play, I, feel, like, her, nowhttp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>deleted</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[delet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>i cant be racist, i have a black friend  \\n\\nl...</td>\n",
       "      <td>i cant be racist, i have a black friend  \\n\\nl...</td>\n",
       "      <td>i cant be racist i have a black friend  \\n\\nlo...</td>\n",
       "      <td>[i, cant, be, racist, i, have, a, black, frien...</td>\n",
       "      <td>[i, cant, be, racist, i, have, a, black, frien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Nope. You're right that they are both smoke an...</td>\n",
       "      <td>nope. you're right that they are both smoke an...</td>\n",
       "      <td>Nope Youre right that they are both smoke and ...</td>\n",
       "      <td>[Nope, Youre, right, that, they, are, both, sm...</td>\n",
       "      <td>[nope, your, right, that, they, are, both, smo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>&amp;lt;That's exactly what it means. especially w...</td>\n",
       "      <td>&amp;lt;that's exactly what it means. especially w...</td>\n",
       "      <td>ltThats exactly what it means especially when ...</td>\n",
       "      <td>[ltThats, exactly, what, it, means, especially...</td>\n",
       "      <td>[ltthat, exactli, what, it, mean, especi, when...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   con                                                txt  \\\n",
       "0    0  Well it's great that he did something about th...   \n",
       "1    0                       You are right Mr. President.   \n",
       "2    0  You have given no input apart from saying I am...   \n",
       "3    0  I get the frustration but the reason they want...   \n",
       "4    0  I am far from an expert on TPP and I would ten...   \n",
       "5    0  Thanks for playing. [I feel like her now](http...   \n",
       "6    0                                          [deleted]   \n",
       "7    0  i cant be racist, i have a black friend  \\n\\nl...   \n",
       "8    0  Nope. You're right that they are both smoke an...   \n",
       "9    0  &lt;That's exactly what it means. especially w...   \n",
       "\n",
       "                                           lower_txt  \\\n",
       "0  well it's great that he did something about th...   \n",
       "1                       you are right mr. president.   \n",
       "2  you have given no input apart from saying i am...   \n",
       "3  i get the frustration but the reason they want...   \n",
       "4  i am far from an expert on tpp and i would ten...   \n",
       "5  thanks for playing. [i feel like her now](http...   \n",
       "6                                          [deleted]   \n",
       "7  i cant be racist, i have a black friend  \\n\\nl...   \n",
       "8  nope. you're right that they are both smoke an...   \n",
       "9  &lt;that's exactly what it means. especially w...   \n",
       "\n",
       "                                           NoPunctxt  \\\n",
       "0  Well its great that he did something about tho...   \n",
       "1                         You are right Mr President   \n",
       "2  You have given no input apart from saying I am...   \n",
       "3  I get the frustration but the reason they want...   \n",
       "4  I am far from an expert on TPP and I would ten...   \n",
       "5  Thanks for playing I feel like her nowhttpsthe...   \n",
       "6                                            deleted   \n",
       "7  i cant be racist i have a black friend  \\n\\nlo...   \n",
       "8  Nope Youre right that they are both smoke and ...   \n",
       "9  ltThats exactly what it means especially when ...   \n",
       "\n",
       "                                           Tokenized  \\\n",
       "0  [Well, its, great, that, he, did, something, a...   \n",
       "1                   [You, are, right, Mr, President]   \n",
       "2  [You, have, given, no, input, apart, from, say...   \n",
       "3  [I, get, the, frustration, but, the, reason, t...   \n",
       "4  [I, am, far, from, an, expert, on, TPP, and, I...   \n",
       "5  [Thanks, for, playing, I, feel, like, her, now...   \n",
       "6                                          [deleted]   \n",
       "7  [i, cant, be, racist, i, have, a, black, frien...   \n",
       "8  [Nope, Youre, right, that, they, are, both, sm...   \n",
       "9  [ltThats, exactly, what, it, means, especially...   \n",
       "\n",
       "                                       PorterStemmer  \n",
       "0  [well, it, great, that, he, did, someth, about...  \n",
       "1                      [you, are, right, Mr, presid]  \n",
       "2  [you, have, given, no, input, apart, from, say...  \n",
       "3  [I, get, the, frustrat, but, the, reason, they...  \n",
       "4  [I, am, far, from, an, expert, on, tpp, and, I...  \n",
       "5  [thank, for, play, I, feel, like, her, nowhttp...  \n",
       "6                                            [delet]  \n",
       "7  [i, cant, be, racist, i, have, a, black, frien...  \n",
       "8  [nope, your, right, that, they, are, both, smo...  \n",
       "9  [ltthat, exactli, what, it, mean, especi, when...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E. Use a Tf-idf vector instead of the word frequency vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.26652051,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.26452993,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.16447604,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.12057085,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.14144756,\n",
       "        0.08435259]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Create text\n",
    "# Here we apply vectorizer to the 1st 10 rows of the txt column. Notice the number of features increases with the number of rows\n",
    "# because there are more text to process. It ay be worth which to get rid of some words 1st.\n",
    "text_data = dataframe['txt'][:20]\n",
    "# Create the tf-idf feature matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(text_data)\n",
    "# Show tf-idf feature matrix\n",
    "feature_matrix.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'well': 474,\n",
       " 'it': 233,\n",
       " 'great': 192,\n",
       " 'that': 423,\n",
       " 'he': 200,\n",
       " 'did': 127,\n",
       " 'something': 402,\n",
       " 'about': 9,\n",
       " 'those': 431,\n",
       " 'beliefs': 60,\n",
       " 'while': 481,\n",
       " 'was': 469,\n",
       " 'in': 219,\n",
       " 'office': 306,\n",
       " 'doubt': 134,\n",
       " 'trump': 446,\n",
       " 'would': 497,\n",
       " 'fight': 161,\n",
       " 'the': 424,\n",
       " 'un': 450,\n",
       " 'for': 168,\n",
       " 'so': 398,\n",
       " 'really': 355,\n",
       " 'happy': 196,\n",
       " 'obama': 304,\n",
       " 'could': 106,\n",
       " 'oh': 307,\n",
       " 'wait': 465,\n",
       " 'you': 502,\n",
       " 'are': 37,\n",
       " 'right': 375,\n",
       " 'mr': 288,\n",
       " 'president': 340,\n",
       " 'have': 199,\n",
       " 'given': 181,\n",
       " 'no': 298,\n",
       " 'input': 225,\n",
       " 'apart': 34,\n",
       " 'from': 176,\n",
       " 'saying': 382,\n",
       " 'am': 26,\n",
       " 'wrong': 498,\n",
       " 'argument': 39,\n",
       " 'clearly': 89,\n",
       " 'get': 179,\n",
       " 'frustration': 177,\n",
       " 'but': 73,\n",
       " 'reason': 356,\n",
       " 'they': 428,\n",
       " 'want': 466,\n",
       " 'them': 425,\n",
       " 'to': 438,\n",
       " 'do': 130,\n",
       " 'way': 470,\n",
       " 'is': 231,\n",
       " 'because': 53,\n",
       " 'its': 234,\n",
       " 'foundation': 172,\n",
       " 'more': 284,\n",
       " 'complex': 98,\n",
       " 'problems': 343,\n",
       " 'as': 41,\n",
       " 'advance': 17,\n",
       " 'grades': 191,\n",
       " 'can': 78,\n",
       " 'decent': 117,\n",
       " 'grade': 190,\n",
       " 'on': 309,\n",
       " 'an': 29,\n",
       " 'sat': 379,\n",
       " 'type': 448,\n",
       " 'test': 420,\n",
       " 'math': 267,\n",
       " 'don': 133,\n",
       " 'understand': 452,\n",
       " 'lot': 256,\n",
       " 'of': 305,\n",
       " 'mathematical': 268,\n",
       " 'ways': 471,\n",
       " 'answer': 31,\n",
       " 'lots': 257,\n",
       " 'times': 437,\n",
       " 'figure': 162,\n",
       " 'out': 318,\n",
       " 'common': 96,\n",
       " 'sense': 390,\n",
       " 'work': 494,\n",
       " 'around': 40,\n",
       " 'questions': 349,\n",
       " 'be': 52,\n",
       " 'ill': 217,\n",
       " 'prepared': 339,\n",
       " 'take': 416,\n",
       " 'college': 93,\n",
       " 'level': 247,\n",
       " 'courses': 108,\n",
       " 'despite': 124,\n",
       " 'above': 10,\n",
       " 'average': 48,\n",
       " 'score': 383,\n",
       " 're': 353,\n",
       " 'not': 300,\n",
       " 'just': 238,\n",
       " 'trying': 447,\n",
       " 'bust': 72,\n",
       " 'kids': 242,\n",
       " 'balls': 51,\n",
       " 'far': 155,\n",
       " 'expert': 153,\n",
       " 'tpp': 441,\n",
       " 'and': 30,\n",
       " 'tend': 419,\n",
       " 'agree': 19,\n",
       " 'had': 194,\n",
       " 'my': 291,\n",
       " 'understanding': 453,\n",
       " 'pushing': 347,\n",
       " 'create': 110,\n",
       " 'economic': 136,\n",
       " 'bulwark': 71,\n",
       " 'against': 18,\n",
       " 'china': 86,\n",
       " 'pacific': 320,\n",
       " 'his': 209,\n",
       " 'administration': 16,\n",
       " 'recognized': 357,\n",
       " 'increasing': 221,\n",
       " 'strength': 409,\n",
       " 'maturity': 269,\n",
       " 'bellicosity': 62,\n",
       " 'see': 386,\n",
       " 'south': 403,\n",
       " 'sea': 384,\n",
       " 'us': 457,\n",
       " 'allies': 23,\n",
       " 'push': 346,\n",
       " 'increased': 220,\n",
       " 'penetration': 322,\n",
       " 'into': 229,\n",
       " 'many': 263,\n",
       " 'emerging': 141,\n",
       " 'markets': 264,\n",
       " 'otherwise': 317,\n",
       " 'naturally': 295,\n",
       " 'align': 21,\n",
       " 'with': 488,\n",
       " 'always': 25,\n",
       " 'thought': 432,\n",
       " 'curious': 113,\n",
       " 'critiques': 111,\n",
       " 'hardly': 197,\n",
       " 'saw': 381,\n",
       " 'mention': 276,\n",
       " 'why': 483,\n",
       " 'has': 198,\n",
       " 'track': 442,\n",
       " 'record': 358,\n",
       " 'someone': 401,\n",
       " 'railroad': 351,\n",
       " 'workers': 496,\n",
       " 'corporate': 105,\n",
       " 'interests': 227,\n",
       " 'there': 427,\n",
       " 'must': 290,\n",
       " 'been': 54,\n",
       " 'felt': 160,\n",
       " 'hugely': 215,\n",
       " 'important': 218,\n",
       " 'use': 458,\n",
       " 'much': 289,\n",
       " 'political': 333,\n",
       " 'capital': 81,\n",
       " 'like': 249,\n",
       " 'maybe': 271,\n",
       " 'better': 64,\n",
       " 'certainly': 84,\n",
       " 'seems': 388,\n",
       " 'yet': 501,\n",
       " 'best': 63,\n",
       " 'manage': 262,\n",
       " 'varied': 460,\n",
       " 'at': 44,\n",
       " 'play': 328,\n",
       " 'however': 213,\n",
       " 'does': 131,\n",
       " 'seem': 387,\n",
       " 'strategic': 407,\n",
       " 'interest': 226,\n",
       " 'if': 216,\n",
       " 'we': 472,\n",
       " 'only': 312,\n",
       " 'throw': 435,\n",
       " 'begin': 56,\n",
       " 'significant': 395,\n",
       " 'withdrawal': 489,\n",
       " 'foreign': 170,\n",
       " 'will': 486,\n",
       " 'definitely': 119,\n",
       " 'move': 286,\n",
       " 'fill': 164,\n",
       " 'void': 464,\n",
       " 'may': 270,\n",
       " 'very': 463,\n",
       " 'looking': 253,\n",
       " 'end': 143,\n",
       " 'western': 477,\n",
       " 'hegemony': 203,\n",
       " 'election': 139,\n",
       " 'ascendency': 42,\n",
       " 'other': 316,\n",
       " 'nationalistic': 293,\n",
       " 'movements': 287,\n",
       " 'britain': 69,\n",
       " 'france': 174,\n",
       " 'elsewhere': 140,\n",
       " 'what': 478,\n",
       " 'sad': 377,\n",
       " 'appears': 35,\n",
       " 'entirely': 144,\n",
       " 'self': 389,\n",
       " 'inflicted': 223,\n",
       " 'nothing': 301,\n",
       " 'forcing': 169,\n",
       " 'retraction': 373,\n",
       " 'developed': 125,\n",
       " 'democracies': 121,\n",
       " 'simply': 396,\n",
       " 'result': 372,\n",
       " 'myopic': 292,\n",
       " 'reactions': 354,\n",
       " 'globalism': 184,\n",
       " 'thanks': 422,\n",
       " 'playing': 329,\n",
       " 'feel': 159,\n",
       " 'her': 204,\n",
       " 'now': 303,\n",
       " 'https': 214,\n",
       " 'thenypost': 426,\n",
       " 'files': 163,\n",
       " 'wordpress': 492,\n",
       " 'com': 94,\n",
       " '2016': 3,\n",
       " '11': 1,\n",
       " '161109': 2,\n",
       " 'clinton': 92,\n",
       " 'camp': 77,\n",
       " '01': 0,\n",
       " 'jpg': 236,\n",
       " 'quality': 348,\n",
       " '90': 7,\n",
       " 'amp': 28,\n",
       " 'strip': 410,\n",
       " 'all': 22,\n",
       " '642': 6,\n",
       " 'lol': 251,\n",
       " 'deleted': 120,\n",
       " 'cant': 80,\n",
       " 'racist': 350,\n",
       " 'black': 65,\n",
       " 'friend': 175,\n",
       " 'lololol': 252,\n",
       " 'vast': 461,\n",
       " 'majority': 261,\n",
       " 'misogynists': 280,\n",
       " 'history': 210,\n",
       " 'weren': 476,\n",
       " 'married': 266,\n",
       " 'women': 490,\n",
       " 'nope': 299,\n",
       " 'both': 68,\n",
       " 'smoke': 397,\n",
       " 'bad': 50,\n",
       " 'lungs': 259,\n",
       " 'tobacco': 439,\n",
       " 'carcinogens': 82,\n",
       " 'plain': 327,\n",
       " 'old': 308,\n",
       " 'heavy': 202,\n",
       " 'metals': 278,\n",
       " 'mj': 281,\n",
       " 'doesn': 132,\n",
       " 'being': 59,\n",
       " 'industrially': 222,\n",
       " 'farmed': 156,\n",
       " 'lt': 258,\n",
       " 'exactly': 149,\n",
       " 'means': 274,\n",
       " 'especially': 146,\n",
       " 'when': 479,\n",
       " 'power': 338,\n",
       " 'existing': 151,\n",
       " 'rights': 376,\n",
       " 'away': 49,\n",
       " 'gt': 193,\n",
       " 'politicians': 334,\n",
       " 'one': 311,\n",
       " 'clear': 88,\n",
       " 'example': 150,\n",
       " 'democrats': 122,\n",
       " 'were': 475,\n",
       " 'gay': 178,\n",
       " 'marriage': 265,\n",
       " 'before': 55,\n",
       " 'hillary': 206,\n",
       " 'evolved': 148,\n",
       " 'respond': 370,\n",
       " 'popular': 337,\n",
       " 'opinion': 313,\n",
       " 'society': 399,\n",
       " 'gives': 182,\n",
       " 'or': 314,\n",
       " 'judges': 237,\n",
       " 'show': 394,\n",
       " 'me': 272,\n",
       " 'mainstream': 260,\n",
       " 'republican': 368,\n",
       " 'taking': 417,\n",
       " 'aren': 38,\n",
       " 'expanding': 152,\n",
       " 've': 462,\n",
       " 'duped': 135,\n",
       " 'by': 74,\n",
       " 'propaganda': 344,\n",
       " 'believe': 61,\n",
       " 'isn': 232,\n",
       " 'canada': 79,\n",
       " 'uk': 449,\n",
       " 'current': 114,\n",
       " 'legal': 245,\n",
       " 'mechanism': 275,\n",
       " 'states': 405,\n",
       " 'secede': 385,\n",
       " 'save': 380,\n",
       " 'successful': 414,\n",
       " 'revolution': 374,\n",
       " 'california': 75,\n",
       " 'referendum': 363,\n",
       " 'laughed': 244,\n",
       " 'federal': 157,\n",
       " 'court': 109,\n",
       " 'meaningless': 273,\n",
       " 'words': 493,\n",
       " 'keep': 241,\n",
       " 'fire': 166,\n",
       " 'contained': 102,\n",
       " 'until': 454,\n",
       " 'anything': 33,\n",
       " 'wants': 468,\n",
       " 'people': 323,\n",
       " 'stop': 406,\n",
       " 'pretending': 341,\n",
       " 'than': 421,\n",
       " 'air': 20,\n",
       " 'declare': 118,\n",
       " 'himself': 208,\n",
       " 'dictator': 126,\n",
       " 'life': 248,\n",
       " 'honestly': 212,\n",
       " 'too': 440,\n",
       " 'upset': 455,\n",
       " 'classic': 87,\n",
       " 'case': 83,\n",
       " 'government': 189,\n",
       " 'department': 123,\n",
       " 'interior': 228,\n",
       " 'giving': 183,\n",
       " 'rats': 352,\n",
       " 'ass': 43,\n",
       " 'native': 294,\n",
       " 'americans': 27,\n",
       " 'gov': 188,\n",
       " 'treaties': 443,\n",
       " 'community': 97,\n",
       " 'organizer': 315,\n",
       " 'supported': 415,\n",
       " 'redistribution': 362,\n",
       " 'wealth': 473,\n",
       " 'wanted': 467,\n",
       " 'money': 283,\n",
       " 'lenders': 246,\n",
       " 'call': 76,\n",
       " 'him': 207,\n",
       " 'loser': 255,\n",
       " 'crying': 112,\n",
       " 'unattractive': 451,\n",
       " 'good': 186,\n",
       " 'time': 436,\n",
       " 'invoke': 230,\n",
       " 'this': 430,\n",
       " 'www': 499,\n",
       " 'reddit': 359,\n",
       " 'politics': 335,\n",
       " 'comments': 95,\n",
       " '5eqcqn': 5,\n",
       " 'stanford_professor_develops_trump_conversion': 404,\n",
       " 'daee57e': 115,\n",
       " 'most': 285,\n",
       " 'characteristics': 85,\n",
       " 'abusers': 12,\n",
       " 'noticed': 302,\n",
       " 'worked': 495,\n",
       " 'disabilities': 129,\n",
       " 'attitude': 45,\n",
       " 'client': 91,\n",
       " 'resistance': 369,\n",
       " 'abuse': 11,\n",
       " 'itself': 235,\n",
       " 'justification': 239,\n",
       " 'once': 310,\n",
       " 'feedback': 158,\n",
       " 'loop': 254,\n",
       " 'established': 147,\n",
       " 'control': 104,\n",
       " 'justified': 240,\n",
       " 'through': 434,\n",
       " 'acquiescence': 14,\n",
       " 'behavior': 58,\n",
       " 'wise': 487,\n",
       " 'escape': 145,\n",
       " 'same': 378,\n",
       " 'holds': 211,\n",
       " 'true': 445,\n",
       " 'abusive': 13,\n",
       " 'relationships': 365,\n",
       " 'prisons': 342,\n",
       " 'police': 332,\n",
       " 'any': 32,\n",
       " 'kind': 243,\n",
       " 'authoritarian': 46,\n",
       " 'regime': 364,\n",
       " 'broader': 70,\n",
       " 'message': 277,\n",
       " 'your': 503,\n",
       " 'behave': 57,\n",
       " 'first': 167,\n",
       " 'place': 326,\n",
       " 'remember': 366,\n",
       " 'over': 319,\n",
       " 'next': 297,\n",
       " 'four': 173,\n",
       " 'years': 500,\n",
       " 'hear': 201,\n",
       " 'trope': 444,\n",
       " 'won': 491,\n",
       " 'appointees': 36,\n",
       " 'boo': 66,\n",
       " 'mike': 279,\n",
       " 'pence': 321,\n",
       " 'protest': 345,\n",
       " 'streets': 408,\n",
       " 'explain': 154,\n",
       " 'death': 116,\n",
       " 'threats': 433,\n",
       " 'got': 187,\n",
       " 'elected': 138,\n",
       " 'course': 107,\n",
       " 'think': 429,\n",
       " 'some': 400,\n",
       " 'poor': 336,\n",
       " 'person': 325,\n",
       " 'give': 180,\n",
       " 'handouts': 195,\n",
       " 'who': 482,\n",
       " 'need': 296,\n",
       " 'submission': 411,\n",
       " 'automatically': 47,\n",
       " 'removed': 367,\n",
       " 'either': 137,\n",
       " 'link': 250,\n",
       " 'shortener': 391,\n",
       " 'redirector': 360,\n",
       " 'allow': 24,\n",
       " 'shorterners': 392,\n",
       " 'redirectors': 361,\n",
       " 'users': 459,\n",
       " 'should': 393,\n",
       " 'able': 8,\n",
       " 'tell': 418,\n",
       " 'where': 480,\n",
       " 'going': 185,\n",
       " 'click': 90,\n",
       " 'encouraged': 142,\n",
       " 'resubmit': 371,\n",
       " 'url': 456,\n",
       " 'points': 331,\n",
       " 'directly': 128,\n",
       " 'content': 103,\n",
       " 'submitting': 412,\n",
       " 'information': 224,\n",
       " 'found': 171,\n",
       " 'here': 205,\n",
       " 'wiki': 484,\n",
       " 'filtereddomains': 165,\n",
       " 'wiki_link_shorteners': 485,\n",
       " '2fredirects': 4,\n",
       " 'bot': 67,\n",
       " 'action': 15,\n",
       " 'performed': 324,\n",
       " 'please': 330,\n",
       " 'contact': 101,\n",
       " 'moderators': 282,\n",
       " 'subreddit': 413,\n",
       " 'compose': 99,\n",
       " 'concerns': 100}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 Encoding Dictionaries of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import library\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create dictionary\n",
    "data_dict = [{\"Red\": 2, \"Blue\": 4},\n",
    "             {\"Red\": 4, \"Blue\": 3},\n",
    "             {\"Red\": 1, \"Yellow\": 2},\n",
    "             {\"Red\": 2, \"Yellow\": 2}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary vectorizer\n",
    "# By default DictVectorizer outputs a sparse matrix that only stores elements with a value other than 0. \n",
    "# This can be very helpful when we have massive matrices (often encountered in natural language processing) and want to \n",
    "# minimize the memory requirements. We can force DictVectorizer to output a dense matrix using sparse=False.\n",
    "\n",
    "dictvectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "# Convert dictionary to feature matrix\n",
    "features = dictvectorizer.fit_transform(data_dict)\n",
    "\n",
    "# View feature matrix\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Blue', 'Red', 'Yellow']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can get the names of each generated feature using the get_feature_names method: # Get feature names\n",
    "feature_names = dictvectorizer.get_feature_names()\n",
    "\n",
    "# View feature names\n",
    "feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Blue</th>\n",
       "      <th>Red</th>\n",
       "      <th>Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Blue  Red  Yellow\n",
       "0   4.0  2.0     0.0\n",
       "1   3.0  4.0     0.0\n",
       "2   0.0  1.0     2.0\n",
       "3   0.0  2.0     2.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# While not necessary, for the sake of illustration we can create a pandas DataFrame to view the output better: \n",
    "# Create dataframe from features\n",
    "pd.DataFrame(features, columns=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create word counts dictionaries for four documents\n",
    "doc_1_word_count = {\"Red\": 2, \"Blue\": 4}\n",
    "doc_2_word_count = {\"Red\": 4, \"Blue\": 3}\n",
    "doc_3_word_count = {\"Red\": 1, \"Yellow\": 2}\n",
    "doc_4_word_count = {\"Red\": 2, \"Yellow\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 2., 0.],\n",
       "       [3., 4., 0.],\n",
       "       [0., 1., 2.],\n",
       "       [0., 2., 2.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list\n",
    "doc_word_counts = [doc_1_word_count,\n",
    "                   doc_2_word_count,\n",
    "                   doc_3_word_count,\n",
    "                   doc_4_word_count]\n",
    "\n",
    "# Convert list of word count dictionaries into feature matrix\n",
    "dictvectorizer.fit_transform(doc_word_counts) \n",
    "# In our toy example there are only three unique words (Red, Yellow, Blue) so there are only three features in our matrix; \n",
    "# however, you can imagine that if each document was actually a book in a university library our feature matrix would be very \n",
    "# large (and then we would want to set spare to True).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.9 Weighting Word Importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x8 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create text\n",
    "text_data = np.array(['I love Brazil. Brazil!',\n",
    "                      'Sweden is best',\n",
    "                      'Germany beats both'])\n",
    "\n",
    "# Create the tf-idf feature matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(text_data)\n",
    "\n",
    "# Show tf-idf feature matrix\n",
    "feature_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.89442719, 0.        ,\n",
       "        0.        , 0.4472136 , 0.        ],\n",
       "       [0.        , 0.57735027, 0.        , 0.        , 0.        ,\n",
       "        0.57735027, 0.        , 0.57735027],\n",
       "       [0.57735027, 0.        , 0.57735027, 0.        , 0.57735027,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show tf-idf feature matrix as dense matrix\n",
    "feature_matrix.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 6,\n",
       " 'brazil': 3,\n",
       " 'sweden': 7,\n",
       " 'is': 5,\n",
       " 'best': 1,\n",
       " 'germany': 4,\n",
       " 'beats': 0,\n",
       " 'both': 2}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show feature names\n",
    "tfidf.vocabulary_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.4 Tokenizing Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'science', 'of', 'today', 'is', 'the', 'technology', 'of', 'tomorrow']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize by word\n",
    "# Load library\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Create text\n",
    "string = \"The science of today is the technology of tomorrow    \"\n",
    "\n",
    "# Tokenize words\n",
    "word_tokenize(string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The science of today is the technology of tomorrow.', 'Tomorrow is today.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize by sentence\n",
    "# Load library\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Create text\n",
    "string = \"The science of today is the technology of tomorrow. Tomorrow is today.\"\n",
    "\n",
    "# Tokenize sentences\n",
    "sent_tokenize(string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.7 Tagging Parts of Speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chris', 'NNP'), ('loved', 'VBD'), ('outdoor', 'RP'), ('running', 'VBG')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Create text\n",
    "text_data = \"Chris loved outdoor running\"\n",
    "word_tokenize(text_data)\n",
    "# Use pre-trained part of speech tagger\n",
    "text_tagged = pos_tag(word_tokenize(text_data))\n",
    "\n",
    "# Show parts of speech\n",
    "text_tagged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a list of tuples with the word and the tag of the part of speech. NLTK uses the Penn Treebank parts for speech tags. Some examples of the Penn Treebank tags are:\n",
    "\n",
    "NNP Proper noun, singular \n",
    "NN Noun, singular or mass \n",
    "RB Adverb \n",
    "VBD Verb, past tense \n",
    "VBG Verb, gerund or present participle \n",
    "JJ Adjective \n",
    "PRP Personal pronoun\n",
    "\n",
    "Once the text has been tagged, we can use the tags to find certain parts of speech. For example, here are all nouns: # Filter words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chris']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word, tag in text_tagged if tag in ['NN','NNS','NNP','NNPS'] ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more realistic situation would be that we have data where every observation contains a tweet and we want to convert those sentences into features for individual parts of speech (e.g., a feature with 1 if a proper noun is present, and 0 otherwise):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PRP', 'VBP', 'VBG', 'DT', 'NN', 'IN', 'NN'],\n",
       " ['JJ', 'NN', 'VBZ', 'DT', 'JJ', 'NN'],\n",
       " ['NNP', 'NNP', 'VBZ', 'DT', 'JJ', 'NN']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer,MultiLabelBinarizer\n",
    "# Create text\n",
    "tweets = [\"I am eating a burrito for breakfast\",\n",
    "          \"Political science is an amazing field\",\n",
    "          \"San Francisco is an awesome city\"]\n",
    "\n",
    "# Create list\n",
    "tagged_tweets = []\n",
    "\n",
    "# Tag each word and each tweet\n",
    "for tweet in tweets:\n",
    "    tweet_tag = pos_tag(word_tokenize(tweet))\n",
    "    tagged_tweets.append([tag for word, tag in tweet_tag])\n",
    "\n",
    "tagged_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 0, 1, 1, 1, 0],\n",
       "       [1, 0, 1, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 1, 1, 1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use one-hot encoding to convert the tags into features\n",
    "\n",
    "one_hot_multi = MultiLabelBinarizer()\n",
    "one_hot_multi.fit_transform(tagged_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DT', 'IN', 'JJ', 'NN', 'NNP', 'PRP', 'VBG', 'VBP', 'VBZ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_multi.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\safar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4623\n",
      "4000\n",
      "623\n"
     ]
    }
   ],
   "source": [
    "# Load library\n",
    "import nltk\n",
    "nltk.download('brown') # Download Brown Corpus\n",
    "from nltk.corpus import brown\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tag import BigramTagger\n",
    "from nltk.tag import TrigramTagger\n",
    "\n",
    "# Get some text from the Brown Corpus, broken into sentences\n",
    "sentences = brown.tagged_sents(categories='news')\n",
    "\n",
    "# Split into 4000 sentences for training and 623 for testing\n",
    "train = sentences[:4000]\n",
    "test = sentences[4000:]\n",
    "print(len(sentences))\n",
    "print(len(train))\n",
    "print(len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8174734002697437"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create backoff tagger\n",
    "unigram = UnigramTagger(train)\n",
    "bigram = BigramTagger(train, backoff=unigram)\n",
    "trigram = TrigramTagger(train, backoff=bigram)\n",
    "\n",
    "# Show accuracy\n",
    "trigram.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.6 Encoding Days of the Week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Thursday\n",
       "1      Sunday\n",
       "2     Tuesday\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "\n",
    "# Create dates\n",
    "dates = pd.Series(pd.date_range(\"2/2/2002\", periods=3, freq=\"M\"))\n",
    "\n",
    "# Show days of the week\n",
    "dates.dt.day_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    6\n",
       "2    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want the output to be a numerical value and therefore more usable as a machine learning feature, \n",
    "# we can use weekday where the days of the week are represented as an integer (Monday is 0): # Show days of the week\n",
    "dates.dt.weekday\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the weekday can be helpful if, for instance, we wanted to compare total sales on Sundays for the past three years. pandas makes creating a feature vector containing weekday information easy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}